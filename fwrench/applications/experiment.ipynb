{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fwrench'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_573572/2205901354.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfire\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mfwrench\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfeats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfwrench\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautows\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mautows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfwrench\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_settings\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msettings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'fwrench'"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import random\n",
    "import copy\n",
    "\n",
    "import fire\n",
    "import fwrench.embeddings as feats\n",
    "import fwrench.utils.autows as autows\n",
    "import fwrench.utils.data_settings as settings\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score\n",
    "from wrench.logging import LoggingHandler\n",
    "\n",
    "def save_labels_to_file(labels, file_name):\n",
    "    \"\"\"\n",
    "    Save the labels to a CSV file.\n",
    "    :param labels: The labels to be saved.\n",
    "    :param file_name: The name of the file to save the labels in.\n",
    "    \"\"\"\n",
    "    np.savetxt(file_name, labels, delimiter=\",\", fmt='%d')\n",
    "\n",
    "    print(f\"Labels saved to {file_name}\")\n",
    "    \n",
    "dataset=\"cifar10\",\n",
    "dataset_home=\"./datasets\",\n",
    "embedding=\"openai\",  # raw | pca | resnet18 | vae\n",
    "# text dataset only\n",
    "extract_fn = \"bert\", # bow | bert | tfidf | sentence_transformer\n",
    "#\n",
    "# Goggles options\n",
    "goggles_method=\"SemiGMM\", # SemiGMM | KMeans | Spectral\n",
    "#\n",
    "lf_selector=\"snuba\",  # snuba | interactive | goggles\n",
    "em_hard_labels=False,  # Use hard or soft labels for end model training\n",
    "n_labeled_points=100,  # Number of points used to train lf_selector\n",
    "#\n",
    "# Snuba options\n",
    "snuba_combo_samples=-1,  # -1 uses all feat. combos\n",
    "# TODO this needs to work for Snuba and IWS\n",
    "snuba_cardinality=1,  # Only used if lf_selector='snuba'\n",
    "iws_cardinality=1,\n",
    "snuba_iterations=23,\n",
    "lf_class_options=\"default\",  # default | comma separated list of lf classes to use in the selection procedure. Example: 'DecisionTreeClassifier,LogisticRegression'\n",
    "#\n",
    "# Interactive Weak Supervision options\n",
    "iws_iterations=25,\n",
    "iws_auto = True,\n",
    "iws_usefulness = 0.6,\n",
    "seed=123,\n",
    "prompt=None,\n",
    "\n",
    "\n",
    "################ HOUSEKEEPING/SELF-CARE ðŸ˜Š ################################\n",
    "random.seed(seed)\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    "    level=logging.INFO,\n",
    "    handlers=[LoggingHandler()],\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "################ LOAD DATASET #############################################\n",
    "\n",
    "if dataset == \"mnist\":\n",
    "    train_data, valid_data, test_data, k_cls, model = settings.get_mnist(\n",
    "        n_labeled_points, dataset_home\n",
    "    )\n",
    "elif dataset == \"fashion_mnist\":\n",
    "    train_data, valid_data, test_data, k_cls, model = settings.get_fashion_mnist(\n",
    "        n_labeled_points, dataset_home\n",
    "    )\n",
    "elif dataset == \"kmnist\":\n",
    "    train_data, valid_data, test_data, k_cls, model = settings.get_kmnist(\n",
    "        n_labeled_points, dataset_home\n",
    "    )\n",
    "elif dataset == \"cifar10\":\n",
    "    train_data, valid_data, test_data, k_cls, model = settings.get_cifar10(\n",
    "        n_labeled_points, dataset_home\n",
    "    )\n",
    "elif dataset == \"spherical_mnist\":\n",
    "    train_data, valid_data, test_data, k_cls, model = settings.get_spherical_mnist(\n",
    "        n_labeled_points, dataset_home\n",
    "    )\n",
    "elif dataset == \"permuted_mnist\":\n",
    "    train_data, valid_data, test_data, k_cls, model = settings.get_permuted_mnist(\n",
    "        n_labeled_points, dataset_home\n",
    "    )\n",
    "elif dataset == \"ecg\":\n",
    "    train_data, valid_data, test_data, k_cls, model = settings.get_ecg(\n",
    "        n_labeled_points, dataset_home\n",
    "    )\n",
    "elif dataset == \"ember\":\n",
    "    train_data, valid_data, test_data, k_cls, model = settings.get_ember_2017(\n",
    "        n_labeled_points, dataset_home\n",
    "    )\n",
    "elif dataset == \"navier_stokes\":\n",
    "    train_data, valid_data, test_data, k_cls, model = settings.get_navier_stokes(\n",
    "        n_labeled_points, dataset_home\n",
    "    )\n",
    "elif dataset == \"imdb\":\n",
    "    if embedding == 'openai' or embedding == 'clip' or embedding == 'clip_zeroshot':\n",
    "        train_data, valid_data, test_data, k_cls, model = settings.get_imdb(\n",
    "            n_labeled_points, dataset_home, extract_fn=None\n",
    "        )\n",
    "    else:\n",
    "        train_data, valid_data, test_data, k_cls, model = settings.get_imdb(\n",
    "            n_labeled_points, dataset_home, extract_fn\n",
    "        )\n",
    "elif dataset == \"yelp\":\n",
    "    if embedding == 'openai' or embedding == 'clip' or embedding == 'clip_zeroshot':\n",
    "        train_data, valid_data, test_data, k_cls, model = settings.get_yelp(\n",
    "            n_labeled_points, dataset_home, extract_fn=None\n",
    "        )\n",
    "    else:\n",
    "        train_data, valid_data, test_data, k_cls, model = settings.get_yelp(\n",
    "            n_labeled_points, dataset_home, extract_fn\n",
    "        )\n",
    "#small dataset, only for testing \n",
    "elif dataset == \"youtube\":\n",
    "    if embedding == 'openai' or embedding == 'clip' or embedding == 'clip_zeroshot':\n",
    "        train_data, valid_data, test_data, k_cls, model = settings.get_youtube(\n",
    "            n_labeled_points, dataset_home, extract_fn=None\n",
    "        )\n",
    "    else:\n",
    "        train_data, valid_data, test_data, k_cls, model = settings.get_youtube(\n",
    "            n_labeled_points, dataset_home, extract_fn\n",
    "        )\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "\n",
    "################ FEATURE REPRESENTATIONS ##################################\n",
    "if embedding == \"raw\":\n",
    "    embedder = feats.FlattenEmbedding()\n",
    "elif embedding == \"pca\":\n",
    "    emb = PCA(n_components=100)\n",
    "    embedder = feats.SklearnEmbedding(emb)\n",
    "elif embedding == \"resnet18\":\n",
    "    embedder = feats.ResNet18Embedding(dataset)\n",
    "elif embedding == \"vae\":\n",
    "    embedder = feats.VAE2DEmbedding()\n",
    "elif embedding == \"clip\":\n",
    "    embedder = feats.CLIPEmbedding()\n",
    "elif embedding == \"clip_zeroshot\":\n",
    "    embedder = feats.ZeroShotCLIPEmbedding(dataset=dataset, prompt=prompt)\n",
    "elif embedding == \"oracle\":\n",
    "    embedder = feats.OracleEmbedding(k_cls)\n",
    "elif embedding == \"openai\":\n",
    "    embedder = feats.OpenAICLIPEmbedding(dataset=dataset, prompt=prompt)\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "\n",
    "if ((embedding == \"resnet18\") and (dataset == \"ecg\")) or ((embedding == \"resnet18\") and (dataset == \"ember\")):\n",
    "    embedder.fit(valid_data, test_data)\n",
    "    valid_data_embed = embedder.transform(valid_data)\n",
    "    test_data_embed = embedder.transform(test_data)\n",
    "    train_data_embed = copy.deepcopy(valid_data_embed)\n",
    "    train_data = copy.deepcopy(valid_data)\n",
    "else:\n",
    "    embedder.fit(train_data, valid_data, test_data)\n",
    "    train_data_embed = embedder.transform(train_data)\n",
    "    valid_data_embed = embedder.transform(valid_data)\n",
    "    test_data_embed = embedder.transform(test_data)\n",
    "\n",
    "################ AUTOMATED WEAK SUPERVISION ###############################\n",
    "if lf_selector == \"snuba\":\n",
    "    test_covered, hard_labels, soft_labels = autows.run_snuba(\n",
    "        valid_data,\n",
    "        train_data,\n",
    "        test_data,\n",
    "        valid_data_embed,\n",
    "        train_data_embed,\n",
    "        test_data_embed,\n",
    "        snuba_cardinality,\n",
    "        snuba_combo_samples,\n",
    "        snuba_iterations,\n",
    "        lf_class_options,\n",
    "        k_cls,\n",
    "        logger,\n",
    "    )\n",
    "elif lf_selector == \"snuba_multiclass\":\n",
    "    test_covered, hard_labels, soft_labels = autows.run_snuba_multiclass(\n",
    "        valid_data,\n",
    "        train_data,\n",
    "        test_data,\n",
    "        valid_data_embed,\n",
    "        train_data_embed,\n",
    "        test_data_embed,\n",
    "        snuba_cardinality,\n",
    "        snuba_combo_samples,\n",
    "        snuba_iterations,\n",
    "        lf_class_options,\n",
    "        k_cls,\n",
    "        logger,\n",
    "    )\n",
    "elif lf_selector == \"iws\":\n",
    "    test_covered, hard_labels, soft_labels = autows.run_iws(\n",
    "        valid_data,\n",
    "        train_data,\n",
    "        test_data,\n",
    "        valid_data_embed,\n",
    "        train_data_embed,\n",
    "        test_data_embed,\n",
    "        iws_cardinality,\n",
    "        iws_iterations,\n",
    "        iws_auto,\n",
    "        iws_usefulness,\n",
    "        lf_class_options,\n",
    "        k_cls,\n",
    "        logger,\n",
    "    )\n",
    "elif lf_selector == \"iws_multiclass\":\n",
    "    test_covered, hard_labels, soft_labels = autows.run_iws_multiclass(\n",
    "        valid_data,\n",
    "        train_data,\n",
    "        test_data,\n",
    "        valid_data_embed,\n",
    "        train_data_embed,\n",
    "        test_data_embed,\n",
    "        iws_cardinality,\n",
    "        iws_iterations,\n",
    "        iws_auto,\n",
    "        lf_class_options,\n",
    "        k_cls,\n",
    "        logger,\n",
    "    )\n",
    "elif lf_selector == \"goggles\":\n",
    "    test_covered, hard_labels, soft_labels = autows.run_goggles(\n",
    "        valid_data,\n",
    "        train_data,\n",
    "        test_data,\n",
    "        valid_data_embed,\n",
    "        train_data_embed,\n",
    "        test_data_embed,\n",
    "        goggles_method,\n",
    "        logger,\n",
    "    )\n",
    "elif lf_selector == \"supervised\":\n",
    "    test_covered, hard_labels, soft_labels = autows.run_supervised(\n",
    "        valid_data,\n",
    "        train_data,\n",
    "        test_data,\n",
    "        valid_data_embed,\n",
    "        train_data_embed,\n",
    "        test_data_embed,\n",
    "        logger,\n",
    "    )\n",
    "elif lf_selector == \"label_prop\":\n",
    "    test_covered, hard_labels, soft_labels = autows.run_label_propagation(\n",
    "        valid_data,\n",
    "        train_data,\n",
    "        test_data,\n",
    "        valid_data_embed,\n",
    "        train_data_embed,\n",
    "        test_data_embed,\n",
    "        logger,\n",
    "    )\n",
    "elif lf_selector == \"clip_zero_shot\" and (\n",
    "    embedding == \"clip_zeroshot\" or embedding == \"oracle\" or embedding == \"openai\"\n",
    "):\n",
    "    test_covered, hard_labels, soft_labels = autows.run_zero_shot_clip(\n",
    "        valid_data,\n",
    "        train_data,\n",
    "        test_data,\n",
    "        valid_data_embed,\n",
    "        train_data_embed,\n",
    "        test_data_embed,\n",
    "        logger,\n",
    "    )\n",
    "else:\n",
    "    raise NotImplementedError\n",
    "\n",
    "# TODO swtich to test set\n",
    "acc = accuracy_score(test_covered.labels, hard_labels)\n",
    "save_labels_to_file(hard_labels, 'hard_labels.csv')\n",
    "cov = float(len(test_covered.labels)) / float(len(test_data.labels))\n",
    "logger.info(f\"label model train acc:    {acc}\")\n",
    "logger.info(f\"label model coverage:     {cov}\")\n",
    "\n",
    "################ TRAIN END MODEL ##########################################\n",
    "# model.fit(\n",
    "#     dataset_train=train_covered,\n",
    "#     y_train=hard_labels if em_hard_labels else soft_labels,\n",
    "#     dataset_valid=valid_data,\n",
    "#     evaluation_step=50,\n",
    "#     metric=\"acc\",\n",
    "#     patience=1000,\n",
    "#     device=device,\n",
    "# )\n",
    "# logger.info(f\"---LeNet eval---\")\n",
    "# acc = model.test(test_data, \"acc\")\n",
    "# logger.info(f\"end model (LeNet) test acc:    {acc}\")\n",
    "################ PROFIT ðŸ¤‘ #################################################\n",
    "print(acc)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AutoWS-Bench-101",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
